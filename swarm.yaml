version: '3.8'

services:
  frontend:
    image: ghcr.io/shuffle/shuffle-frontend:nightly
    hostname: shuffle-frontend
    networks:
      - shuffle
    env_file: .env
    deploy:
      replicas: ${SWARM_NODE_COUNT}
      restart_policy:
        condition: any
        delay: 10s
        max_attempts: 0  # Unlimited restarts for resilience
        window: 60s
      placement:
        max_replicas_per_node: 1
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback

  backend:
    image: ghcr.io/shuffle/shuffle-backend:nightly
    hostname: shuffle-backend
    networks:
      - shuffle
      - swarm_executions
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - shuffle-apps:/shuffle-apps
      - shuffle-files:/shuffle-files
    env_file: .env
    deploy:
      replicas: ${SWARM_NODE_COUNT}
      restart_policy:
        condition: any
        delay: 10s
        max_attempts: 0  # Unlimited restarts for resilience
        window: 60s
      placement:
        max_replicas_per_node: 1
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback

  orborus:
    image: ghcr.io/shuffle/shuffle-orborus:nightly
    hostname: shuffle-orborus
    networks:
      - shuffle
      - swarm_executions
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    env_file: .env
    environment:
      - SHUFFLE_APP_SDK_TIMEOUT=300
      - BASE_URL=http://shuffle-backend:5001
      - SHUFFLE_STATS_DISABLED=true
      - SHUFFLE_SWARM_CONFIG=run
      - SHUFFLE_WORKER_IMAGE=ghcr.io/shuffle/shuffle-worker:latest
      - SHUFFLE_APP_REPLICA=${SHUFFLE_APP_REPLICA}
      - SHUFFLE_WORKER_SERVER_URL=http://shuffle-workers:33333
      - SHUFFLE_SWARM_NETWORK_NAME=shuffle_swarm_executions
      - SHUFFLE_ORBORUS_EXECUTION_CONCURRENCY=${SHUFFLE_ORBORUS_EXECUTION_CONCURRENCY}
    deploy:
      replicas: ${SWARM_NODE_COUNT}
      restart_policy:
        condition: any
        delay: 10s
        max_attempts: 0  # Unlimited restarts for resilience
        window: 60s
      placement:
        preferences:
          - spread: node.id

  opensearch:
    image: opensearchproject/opensearch:3.0.0
    env_file: .env
    environment:
      - OPENSEARCH_JAVA_OPTS=${OPENSEARCH_JAVA_OPTS}
      - bootstrap.memory_lock=false
      - DISABLE_PERFORMANCE_ANALYZER_AGENT_CLI=true
      - cluster.routing.allocation.disk.threshold_enabled=true
      - cluster.name=shuffle-cluster
      - node.name={{.Node.Hostname}}-{{.Task.Slot}}
      - node.store.allow_mmap=false
      - network.host=0.0.0.0
      - discovery.seed_hosts=tasks.opensearch
      - cluster.initial_cluster_manager_nodes={{.Node.Hostname}}-{{.Task.Slot}}
      - action.auto_create_index=true
      - DISABLE_SECURITY_PLUGIN=true
      # Dynamic thread pool settings based on node count
      - thread_pool.search.size=${THREAD_POOL_SEARCH_SIZE}
      - thread_pool.search.queue_size=${THREAD_POOL_SEARCH_QUEUE}
      - thread_pool.write.size=${THREAD_POOL_WRITE_SIZE}
      - thread_pool.write.queue_size=${THREAD_POOL_WRITE_QUEUE}
      - thread_pool.get.size=${THREAD_POOL_GET_SIZE}
      - thread_pool.get.queue_size=${THREAD_POOL_GET_QUEUE}
      # Note: thread_pool.bulk.* removed - deprecated in OpenSearch 3.0, write thread pool handles bulk operations
      # Circuit breaker settings - dynamically adjusted
      - indices.breaker.total.limit=${CIRCUIT_BREAKER_TOTAL_LIMIT}
      - indices.breaker.request.limit=${CIRCUIT_BREAKER_REQUEST_LIMIT}
      - indices.breaker.fielddata.limit=${CIRCUIT_BREAKER_FIELDDATA_LIMIT}
      - network.breaker.inflight_requests.limit=${CIRCUIT_BREAKER_NETWORK_LIMIT}
      # Memory settings
      - indices.memory.index_buffer_size=30%
      - indices.memory.min_index_buffer_size=256mb
      - indices.queries.cache.size=20%
      - indices.requests.cache.size=10%
      - indices.fielddata.cache.size=20%
      # Note: index.* settings removed - these are index-level settings that cannot be set at node level in OpenSearch 3.0
      # Search settings
      - search.default_search_timeout=60s
      - search.max_buckets=50000
      - search.allow_expensive_queries=false
      # Note: bulk.* settings removed - not supported in OpenSearch 3.0
      # HTTP settings
      - http.max_content_length=200mb
      - http.max_header_size=16kb
      - http.max_initial_line_length=8kb
      # Disk watermarks
      - cluster.routing.allocation.disk.watermark.low=80%
      - cluster.routing.allocation.disk.watermark.high=90%
      - cluster.routing.allocation.disk.watermark.flood_stage=95%
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    networks:
      - shuffle
    volumes:
      - /opt/shuffle/shuffle-database:/usr/share/opensearch/data
    deploy:
      replicas: ${SWARM_NODE_COUNT}
      endpoint_mode: dnsrr
      restart_policy:
        condition: any
        delay: 15s
        max_attempts: 0  # Unlimited restarts for resilience
        window: 60s
      update_config:
        parallelism: 1
        delay: 30s
        failure_action: rollback
      placement:
        max_replicas_per_node: 1
        preferences:
          - spread: node.id
      resources:
        limits:
          memory: 6G  # Reduced for stability
        reservations:
          memory: 4G


  load-balancer:
    image: nginx:alpine
    ports:
      - "3001:80"
      - "3443:443"
    networks:
      - shuffle
    configs:
      - source: nginx_main_conf
        target: /etc/nginx/nginx.conf
    deploy:
      replicas: ${SWARM_NODE_COUNT}
      restart_policy:
        condition: any
        delay: 10s  # Faster restart
        max_attempts: 0  # Unlimited restarts for resilience
        window: 60s
      placement:
        max_replicas_per_node: 1

  memcached:
    image: memcached:latest
    hostname: shuffle_memcached
    networks:
      - shuffle
      - swarm_executions
    env_file: .env
    deploy:
      replicas: ${SWARM_NODE_COUNT}
      restart_policy:
        condition: any
        delay: 10s
        max_attempts: 0  # Unlimited restarts for resilience
        window: 60s
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

configs:
  nginx_main_conf:
    file: ./nginx-main.conf

volumes:
  # NFS volumes - shared across all swarm nodes (NFSv3 with pinned mountd)
  shuffle-apps:
    driver: local
    driver_opts:
      type: nfs
      o: "addr=${NFS_MASTER_IP},nfsvers=3,proto=tcp,rw,soft,intr,port=2049,mountport=51771,resvport,nolock,timeo=600,retrans=2"
      device: ":/srv/nfs/shuffle-apps"

  shuffle-files:
    driver: local
    driver_opts:
      type: nfs
      o: "addr=${NFS_MASTER_IP},nfsvers=3,proto=tcp,rw,soft,intr,port=2049,mountport=51771,resvport,nolock,timeo=600,retrans=2"
      device: ":/srv/nfs/shuffle-files"

  shuffle-database:
    driver: local
    driver_opts:
      type: nfs
      o: "addr=${NFS_MASTER_IP},nfsvers=3,proto=tcp,rw,soft,intr,port=2049,mountport=51771,resvport,nolock,timeo=600,retrans=2"
      device: ":/srv/nfs/shuffle-database"


networks:
  shuffle:
    driver: overlay
    attachable: true
    driver_opts:
      com.docker.network.driver.mtu: "1500"
  swarm_executions:
    driver: overlay
    attachable: true
    driver_opts:
      com.docker.network.driver.mtu: "1500"