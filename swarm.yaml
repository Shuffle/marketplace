version: '3.8'

services:
  frontend:
    image: ghcr.io/shuffle/shuffle-frontend:nightly
    hostname: shuffle-frontend
    networks:
      - shuffle
    env_file: .env
    deploy:
      replicas: ${SWARM_NODE_COUNT}
      restart_policy:
        condition: any
        delay: 10s
        max_attempts: 0  # Unlimited restarts for resilience
        window: 60s
      placement:
        max_replicas_per_node: 1
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback

  backend:
    image: ghcr.io/shuffle/shuffle-backend:nightly
    hostname: shuffle-backend
    networks:
      - shuffle
      - swarm_executions
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - shuffle-apps:/shuffle-apps
      - shuffle-files:/shuffle-files
    env_file: .env
    deploy:
      replicas: ${SWARM_NODE_COUNT}
      restart_policy:
        condition: any
        delay: 10s
        max_attempts: 0  # Unlimited restarts for resilience
        window: 60s
      placement:
        max_replicas_per_node: 1
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback

  orborus:
    image: ghcr.io/shuffle/shuffle-orborus:nightly
    hostname: shuffle-orborus
    networks:
      - shuffle
      - swarm_executions
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    env_file: .env
    environment:
      - SHUFFLE_APP_SDK_TIMEOUT=300
      - BASE_URL=http://shuffle-backend:5001
      - SHUFFLE_STATS_DISABLED=true
      - SHUFFLE_SWARM_CONFIG=run
      - SHUFFLE_WORKER_IMAGE=ghcr.io/shuffle/shuffle-worker:latest
      - SHUFFLE_APP_REPLICA=3
      - SHUFFLE_WORKER_SERVER_URL=http://shuffle-workers:33333
      - SHUFFLE_SWARM_NETWORK_NAME=shuffle_swarm_executions
    deploy:
      replicas: ${SWARM_NODE_COUNT}
      restart_policy:
        condition: any
        delay: 10s
        max_attempts: 0  # Unlimited restarts for resilience
        window: 60s
      placement:
        preferences:
          - spread: node.id

  opensearch:
    image: opensearchproject/opensearch:3.0.0
    env_file: .env
    environment:
      - OPENSEARCH_JAVA_OPTS=${OPENSEARCH_JAVA_OPTS}
      - bootstrap.memory_lock=false
      - DISABLE_PERFORMANCE_ANALYZER_AGENT_CLI=true
      - cluster.routing.allocation.disk.threshold_enabled=true
      - cluster.name=shuffle-cluster
      - node.name=shuffle-opensearch-{{.Task.Slot}}
      - node.store.allow_mmap=false
      - discovery.type=${OPENSEARCH_DISCOVERY_TYPE}
      - cluster.initial_master_nodes=${OPENSEARCH_INITIAL_MASTERS}
      - network.host=0.0.0.0
      - action.auto_create_index=true
      - DISABLE_SECURITY_PLUGIN=true
      # Production thread pool settings
      - thread_pool.search.size=16
      - thread_pool.search.queue_size=10000
      - thread_pool.write.size=8
      - thread_pool.write.queue_size=1000
      - thread_pool.get.size=8
      - thread_pool.get.queue_size=5000
      - thread_pool.bulk.size=8
      - thread_pool.bulk.queue_size=200
      # Circuit breaker settings
      - indices.breaker.total.limit=85%
      - indices.breaker.request.limit=60%
      - indices.breaker.fielddata.limit=40%
      - indices.breaker.in_flight_requests.limit=100%
      # Memory settings
      - indices.memory.index_buffer_size=30%
      - indices.memory.min_index_buffer_size=256mb
      - indices.queries.cache.size=20%
      - indices.requests.cache.size=10%
      - indices.fielddata.cache.size=20%
      # Indexing performance
      - index.refresh_interval=10s
      - index.number_of_shards=3
      - index.number_of_replicas=${OPENSEARCH_INDEX_REPLICAS}
      - index.translog.flush_threshold_size=1gb
      - index.translog.durability=async
      # Search settings
      - search.default_search_timeout=60s
      - search.max_buckets=50000
      - search.allow_expensive_queries=false
      # Bulk settings
      - bulk.queue_size=1000
      - bulk.max_operations=10000
      - bulk.max_size=100mb
      # HTTP settings
      - http.max_content_length=200mb
      - http.max_header_size=16kb
      - http.max_initial_line_length=8kb
      # Disk watermarks
      - cluster.routing.allocation.disk.watermark.low=80%
      - cluster.routing.allocation.disk.watermark.high=90%
      - cluster.routing.allocation.disk.watermark.flood_stage=95%
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    networks:
      - shuffle
    volumes:
      - shuffle-database:/usr/share/opensearch/data
    deploy:
      replicas: ${OPENSEARCH_REPLICAS}
      restart_policy:
        condition: any
        delay: 15s
        max_attempts: 0  # Unlimited restarts for resilience
        window: 60s
      update_config:
        parallelism: 1
        delay: 30s
        failure_action: rollback
      placement:
        max_replicas_per_node: 1
        preferences:
          - spread: node.id
      resources:
        limits:
          memory: 6G  # Reduced for stability
        reservations:
          memory: 4G

  # OpenSearch Circuit Breaker - handles database failures gracefully
  opensearch-circuit-breaker:
    image: nginx:alpine
    networks:
      - shuffle
    configs:
      - source: opensearch_circuit_breaker_conf
        target: /etc/nginx/nginx.conf
    deploy:
      replicas: 1
      restart_policy:
        condition: any
        delay: 10s
        max_attempts: 0
        window: 60s
      placement:
        constraints:
          - node.role==manager

  load-balancer:
    image: nginx:alpine
    ports:
      - "3001:80"
      - "3443:443"
    networks:
      - shuffle
    volumes:
      - nginx-config:/nginx-config:ro
    command: sh -c "cp /nginx-config/nginx-main.conf /etc/nginx/nginx.conf && nginx -g 'daemon off;'"
    deploy:
      replicas: ${SWARM_NODE_COUNT}
      restart_policy:
        condition: any
        delay: 10s  # Faster restart
        max_attempts: 0  # Unlimited restarts for resilience
        window: 60s
      placement:
        max_replicas_per_node: 1

  memcached:
    image: memcached:latest
    hostname: shuffle_memcached
    networks:
      - shuffle
    env_file: .env
    deploy:
      replicas: 1
      restart_policy:
        condition: any
        delay: 10s
        max_attempts: 0  # Unlimited restarts for resilience
        window: 60s
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

configs:
  opensearch_circuit_breaker_conf:
    file: ./opensearch-circuit-breaker.conf

volumes:
  # NFS volumes - shared across all swarm nodes (NFSv3 with pinned mountd)
  shuffle-apps:
    driver: local
    driver_opts:
      type: nfs
      o: "addr=${NFS_MASTER_IP},nfsvers=3,proto=tcp,rw,soft,intr,port=2049,mountport=51771,resvport,nolock,timeo=600,retrans=2"
      device: ":/srv/nfs/shuffle-apps"

  shuffle-files:
    driver: local
    driver_opts:
      type: nfs
      o: "addr=${NFS_MASTER_IP},nfsvers=3,proto=tcp,rw,soft,intr,port=2049,mountport=51771,resvport,nolock,timeo=600,retrans=2"
      device: ":/srv/nfs/shuffle-files"

  shuffle-database:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/shuffle/shuffle-database

  nginx-config:
    driver: local
    driver_opts:
      type: nfs
      o: "addr=${NFS_MASTER_IP},nfsvers=3,proto=tcp,ro,soft,intr,port=2049,mountport=51771,resvport,nolock,timeo=600,retrans=2"
      device: ":/srv/nfs/nginx-config"

networks:
  shuffle:
    driver: overlay
    attachable: true
    driver_opts:
      com.docker.network.driver.mtu: "1500"
  swarm_executions:
    driver: overlay
    attachable: true